{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Изучение-данных-из-файла,-предобработка\" data-toc-modified-id=\"Изучение-данных-из-файла,-предобработка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Изучение данных из файла, предобработка</a></span></li><li><span><a href=\"#Разбиение-данных-на-обучающую,-валидационную-и-тестовую-выборки\" data-toc-modified-id=\"Разбиение-данных-на-обучающую,-валидационную-и-тестовую-выборки-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Разбиение данных на обучающую, валидационную и тестовую выборки</a></span></li><li><span><a href=\"#Исследование-моделей\" data-toc-modified-id=\"Исследование-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Исследование моделей</a></span></li><li><span><a href=\"#Проверка-модели-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-модели-на-тестовой-выборке-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Проверка модели на тестовой выборке</a></span></li><li><span><a href=\"#Проверка-модели-на-вменяемость\" data-toc-modified-id=\"Проверка-модели-на-вменяемость-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Проверка модели на вменяемость</a></span></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Общий вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов сотовой связи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оператор сотовой связи «Мегалайн» хочет построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра». Для анализа имеются данные о поведении клиентов, которые уже перешли на эти тарифы. \n",
    "\n",
    "\n",
    "В проекте нужно построить модель для задачи классификации, которая выберет подходящий тариф. После построения модели следует проверить её на тестовой выборке и получить максимально большое значение метрики *accuracy* (не менее 0,75)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изучение данных из файла, предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные из файла и ознакомимся с таблицей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    main_data = pd.read_csv('users_behavior.csv')\n",
    "except:\n",
    "    main_data = pd.read_csv('/datasets/users_behavior.csv')\n",
    "main_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в таблице отсутствуют пропуски, имена столбцов корректные. Посмотрим теперь сами данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбцы calls и messages имеют вещественный тип данных, а должны иметь целочисленный тип.  Выполним далее преобразование.\n",
    "\n",
    "Столбцы minutes и mb_used могут хранить данные с дробными значениями (к примеру, абонент проговорил 311,9 минут), но это не имеет практического смысла. Мобильный оператор всё равно будет округлять минуты в большую сторону. Дробные значения мегабайтов интернет-трафика тоже не актуальны. Поэтому эти два столбца должны тоже иметь целочисленный тип. Выполним далее преобразование с округлением в большую сторону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['calls'] = main_data['calls'].astype('int')\n",
    "main_data['messages'] = main_data['messages'].astype('int')\n",
    "main_data['minutes'] = np.ceil(main_data['minutes']).astype('int')\n",
    "main_data['mb_used'] = np.ceil(main_data['mb_used']).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   calls     3214 non-null   int32\n",
      " 1   minutes   3214 non-null   int32\n",
      " 2   messages  3214 non-null   int32\n",
      " 3   mb_used   3214 non-null   int32\n",
      " 4   is_ultra  3214 non-null   int64\n",
      "dtypes: int32(4), int64(1)\n",
      "memory usage: 75.5 KB\n"
     ]
    }
   ],
   "source": [
    "main_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразования типов столбцов прошли корректно. Исследуем теперь баланс классов в столбце с целевым признаком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в столбце целевых признаков более чем в два раза больше значений False, чем True. Это следует учесть при подготовке выборок в дальнейшем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение данных на обучающую, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как для исследований нет отдельной спрятанной тестовой выборки, то придётся исходный набор данных делить на три выборки: обучающую, валидационную и тестовую в соотношении 60%:20%:20%. Для получения таких выборок используем функцию train_test_split, вызвав её два раза. При этом при каждом вызове функции будем использовать стратификацию по целевым признакам, так как они распределены неравномерно в исходной таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data, test_data = train_test_split(\n",
    "    main_data,test_size=0.2, stratify=main_data['is_ultra'], random_state=123)\n",
    "train_data, valid_data = train_test_split(\n",
    "    temp_data,test_size = 0.25, stratify=temp_data['is_ultra'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 5)\n",
      "(643, 5)\n",
      "(643, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение данных на три выборки прошло успешно. Теперь выделим из выборок обычные и целевые признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_data.drop(columns=['is_ultra'])\n",
    "train_target = train_data['is_ultra']\n",
    "valid_features = valid_data.drop(columns=['is_ultra'])\n",
    "valid_target = valid_data['is_ultra']\n",
    "test_features = test_data.drop(columns=['is_ultra'])\n",
    "test_target = test_data['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим как распределены целевые признаки во всех выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка:\n",
      " 0    1337\n",
      "1     591\n",
      "Name: is_ultra, dtype: int64 \n",
      "\n",
      "Валидационная выборка:\n",
      " 0    446\n",
      "1    197\n",
      "Name: is_ultra, dtype: int64 \n",
      "\n",
      "Тестовая выборка:\n",
      " 0    446\n",
      "1    197\n",
      "Name: is_ultra, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Обучающая выборка:\\n', train_target.value_counts(), '\\n')\n",
    "print('Валидационная выборка:\\n', valid_target.value_counts(), '\\n')\n",
    "print('Тестовая выборка:\\n', test_target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение целевых признаков в разных выборках выглядит схожим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем исследовать три вида моделей: дерево решений, случайный лес и логистическую регрессию. При этом в первых двух видах моделей попробуем подобрать оптимальные гиперпараметры, проверяя качество моделей на валидационной выборке. \n",
    "В алгоритмы обучения моделей добавим взвешивание классов (аргумент class_weight). Для ускорения обучения моделей \"Случайный лес\" и логистической регрессии применим гиперпараметр n_jobs=-1, что означает использование всех ядер и потоков процессора.\n",
    "\n",
    "Начнём с модели \"Дерево решений\". Будем изменять значения гиперпараметра max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель дерева решений имеет глубину 5, значение accuracy=0.788\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, class_weight='balanced', random_state=123)\n",
    "    model.fit(train_features, train_target)\n",
    "    result = model.score(valid_features, valid_target)\n",
    "    if result > best_result:\n",
    "        best_depth = depth\n",
    "        best_result = result\n",
    "\n",
    "print(f'Лучшая модель дерева решений имеет глубину {best_depth}, значение accuracy={best_result:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь исследуем модель \"Случайный лес\". Будем изменять значения гиперпараметров n_estimators, max_depth и criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель случайного леса имеет количество деревьев 30, глубину 10, критерий entropy, значение accuracy=0.806\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "best_crit= ''\n",
    "for est in range(5, 101, 5):\n",
    "    for depth in range (1, 21):\n",
    "        for crit in ['gini', 'entropy']:\n",
    "            model = RandomForestClassifier(n_estimators=est, max_depth=depth, criterion=crit, class_weight='balanced',\n",
    "                                            n_jobs=-1, random_state=123) \n",
    "            model.fit(train_features, train_target) \n",
    "            result = model.score(valid_features, valid_target) \n",
    "            if result > best_result:\n",
    "                best_est = est\n",
    "                best_depth = depth\n",
    "                best_crit = crit\n",
    "                best_result = result\n",
    "\n",
    "print(f'Лучшая модель случайного леса имеет количество деревьев {best_est}, глубину {best_depth}, критерий {best_crit}, ' \n",
    "      f'значение accuracy={best_result:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоследок, исследуем модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель логистической регрессии имеет значение accuracy=0.753\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200, random_state=123, n_jobs=-1) \n",
    "model.fit(train_features, train_target) \n",
    "result = model.score(valid_features, valid_target)\n",
    "print(f'Модель логистической регрессии имеет значение accuracy={result:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** наилучший результат (самое большое значение accuracy) показала модель случайного леса RandomForestClassifier с настроенными гиперпараметрами n_estimators, max_depth и criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем модель со значениями гиперпараметров, которые показали наилучший результат при исследовании на валидационной выборке. Но теперь проверять работу модели будем с использованием тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение accuracy при проверке выбранной модели на тестовой выборке: 0.802\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(n_estimators=best_est, max_depth=best_depth, criterion=best_crit, n_jobs=-1, random_state=123) \n",
    "best_model.fit(train_features, train_target) \n",
    "result = best_model.score(test_features, test_target)\n",
    "print(f'Значение accuracy при проверке выбранной модели на тестовой выборке: {result:.3F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь улучшить результат и обучить выбранную модель на суммарной тренировочной и валидационной выборках. В этом случае у модели будет больше данных для обучения. Ранее, я делил исходный датасет на три выборки функцией train_test_split в два этапа. На первом этапе данные разделились на тестовую и временную выборку в соотношении 20% к 80%. Эта временная выборка по сути и есть суммарная тренировочная и валидационная. Сформируем из неё признаки и целевые признаки, а затем заново обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение accuracy при проверке на тестовой выборке заново обученной модели на суммарной тренировочной и валидационной выборках : 0.801\n"
     ]
    }
   ],
   "source": [
    "train_valid_features = temp_data.drop(columns=['is_ultra'])\n",
    "train_valid_target = temp_data['is_ultra']\n",
    "best_model.fit(train_valid_features, train_valid_target)\n",
    "result = best_model.score(test_features, test_target)\n",
    "print(f'Значение accuracy при проверке на тестовой выборке заново обученной модели на суммарной ' \n",
    "      f'тренировочной и валидационной выборках : {result:.3F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат серьёзно не изменился."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** выбранная модель случайного леса успешно прошла проверку и показала значение accuracy выше 0.75. Попытки использовать для обучения модели суммарную обучающую и валидационную выборки значительного результата не принесли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка модели на вменяемость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки выбранной модели на вменяемость сравним её качество с качеством модели константного предсказания - DummyClassifier. Эта модель будет предсказывать одинаковые значения, которые встречаются в тренировочном наборе целевых признаков наиболее часто. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение accuracy при проверке константной модели на тестовой выборке: 0.694\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='most_frequent', random_state=123)\n",
    "dummy_model.fit(train_features, train_target)\n",
    "result = dummy_model.score(test_features, test_target)\n",
    "print(f'Значение accuracy при проверке константной модели на тестовой выборке: {result:.3F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, значение accuracy у константной модели невысокое. У выбранной модели случайного леса оно существенно выше. Но сравним качество этих моделей, построив матрицу ошибок. \n",
    "\n",
    "Посмотрим ещё раз как распределены значения в тестовом наборе целевых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    446\n",
       "1    197\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[446,   0],\n",
       "       [197,   0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_pred = dummy_model.predict(test_features)\n",
    "confusion_matrix(test_target, dummy_pred, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Константная модель определила, что в наборе тренировочных целевых признаков преобладают значения \"False\". И сделала такие предсказания для тестовой выборки. Все значения \"False\" были автоматически угаданы, но при этом вышли ложные предсказания для \"True\".\n",
    "\n",
    "Построим теперь матрицу ошибок для выбранной в проекте модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выбранная в проекте модель допустила 100 ложноотрицательных ответов и 28 ложноположительных\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_model.predict(test_features)\n",
    "tn, fp, fn, tp = confusion_matrix(test_target, best_pred, labels = [0, 1]).ravel()\n",
    "print(f'Выбранная в проекте модель допустила {fn} ложноотрицательных ответов и {fp} ложноположительных')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В проекте была произведена минимальная преобработка исходных данных и их разделение на обучающую, валидационную и тестовую выборки. При разделении на выборки была применена стратификация по целевому признаку, что в дальнейшем улучшило метрику качества моделей.\n",
    "\n",
    "Далее в проекте были построены три модели машинного обучения: дерево решений, случайный лес, логистическая регрессия. Для моделей подбирались значения их гиперпараметров с целью улучшения качества и получения более высокого значения accuracy. \n",
    "Наилучшие результаты удалось получить в модели случайного леса с определёнными значениями гиперпараметров. \n",
    "\n",
    "Выбранная модель успешно прошла проверку на тестовой выборке и показала значение accuracy более 0,75. Также модель прошла проверку на адекватность в сравнении с константной моделью. Попытки использовать для обучения модели суммарную обучающую и валидационную выборки значительного результата не принесли."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 51,
    "start_time": "2022-05-28T04:32:28.406Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
